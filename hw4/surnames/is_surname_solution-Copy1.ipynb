{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read data.\n",
    "linear_train = pd.read_csv('data/linear_train.txt', header=None).dropna()\n",
    "linear_ans_example = pd.read_csv('data/linear_ans_example.txt').dropna()\n",
    "linear_test = pd.read_csv('data/linear_test.txt', header=None).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_x = linear_train[0]\n",
    "full_y = linear_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_last_n_letters(array, n):\n",
    "    return [word[-(n*2):] for word in array]\n",
    "\n",
    "def append_hash_back(array):\n",
    "    return [word + \"#\" for word in array]\n",
    "\n",
    "def append_dollar_front(array):\n",
    "    return [\"$\" + word for word in array]\n",
    "\n",
    "def append_front_back(array):\n",
    "    return [\"$\" + word + \"#\" for word in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def isCapitalized(word):\n",
    "    capitals = ['А','Б','В','Г','Д','Е','Ё','Ж','З','И','Й','К','Л','М','Н','О',\n",
    "           'П','Р','С','Т','У','Ф','Х','Ц','Ч','Ш','Щ','Ъ','Ы','Ь','Э','Ю','Я']\n",
    "    return int(word[0:2] in capitals and not (word[2:4] in capitals))\n",
    "\n",
    "def vowel_count(word):\n",
    "    vowels = ['А','Е','Ё','И','О','У','Ы','Э','Ю','Я',\n",
    "              'а','е','ё','и','о','у','ы','э','ю','я']\n",
    "    retval = 0\n",
    "    for i in range (len(word)/2):\n",
    "        if word[i*2 : (i*2)+2] in vowels:\n",
    "            retval+=1\n",
    "    return retval\n",
    "\n",
    "def consonant_count(word):\n",
    "    consonants = ['Б','В','Г','Д','Ж','З','Й','К','Л','М','Н','П','Р','С','Т','Ф','Х','Ц','Ч','Ш','Щ','Ъ','Ь',\n",
    "                  'б','в','г','д','ж','з','й','к','л','м','н','п','р','с','т','ф','х','ц','ч','ш','щ','ъ','ь',]\n",
    "    retval = 0\n",
    "    for i in range (len(word)/2):\n",
    "        if word[i*2 : (i*2)+2] in consonants:\n",
    "            retval+=1\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_feature(functor,surnames_train, surnames_test, x_train, x_test):\n",
    "    first_capital_train = np.array([functor(word) for word in surnames_train]).reshape([-1,1])\n",
    "    x_train = hstack((x_train, coo_matrix(first_capital_train)))\n",
    "    \n",
    "    first_capital_test = np.array([functor(word) for word in surnames_test]).reshape([-1,1])\n",
    "    x_test = hstack((x_test, coo_matrix(first_capital_test)))\n",
    "    return (x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_to_csv(y, csv_name):\n",
    "    try :\n",
    "        os.mkdir(\"results\")\n",
    "    except:\n",
    "        pass\n",
    "    output = pd.DataFrame(data=y, columns=['Answer'])\n",
    "    output.index.name = 'Id'\n",
    "    output.to_csv(path_or_buf = './results/' + csv_name, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_result(clf, x_train_l, y_train_l, x_test_l):\n",
    "    count_vect = CountVectorizer(ngram_range=(4*2,8*2), decode_error='ignore', lowercase=True, analyzer='char')\n",
    "        \n",
    "    x_train_new0 = count_vect.fit_transform(x_train_l)\n",
    "    x_test_new0 = count_vect.transform(x_test_l)\n",
    "    \n",
    "    print(count_vect.get_feature_names()[0])\n",
    "    \n",
    "    \n",
    "    x_train_new0, x_test_new0 = add_feature(isCapitalized, x_train_l, x_test_l, x_train_new0, x_test_new0)\n",
    "    x_train_new0, x_test_new0 = add_feature(vowel_count, x_train_l, x_test_l, x_train_new0, x_test_new0)\n",
    "    x_train_new0, x_test_new0 = add_feature(consonant_count, x_train_l, x_test_l, x_train_new0, x_test_new0)\n",
    "\n",
    "    clf = clf.fit(x_train_new0, y_train_l)\n",
    "    return clf.predict(x_test_new0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68 ms, sys: 0 ns, total: 68 ms\n",
      "Wall time: 66.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train, x_test, y_train, y_test = train_test_split(full_x, full_y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " «газпро\n",
      "0.697433151456\n",
      "CPU times: user 21.6 s, sys: 64 ms, total: 21.6 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(roc_auc_score(get_result(LinearSVC(), append_front_back(x_train), y_train, append_front_back(x_test)), \n",
    "                     y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " «газпро\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(4*2,8*2), decode_error='ignore', lowercase=True, analyzer='char')\n",
    "\n",
    "x_train_new0 = count_vect.fit_transform(x_train)\n",
    "print(count_vect.get_feature_names()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719151770351\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(get_result(LinearSVC(), append_front_back(x_train), y_train, append_front_back(x_test)), \n",
    "                     y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.600625377976\n",
      "CPU times: user 4.91 s, sys: 60 ms, total: 4.97 s\n",
      "Wall time: 4.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(roc_auc_score(get_result(MultinomialNB(), append_hash_back(x_train), y_train, append_hash_back(x_test)), \n",
    "                     y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# result = get_result(LogisticRegression(), linear_train[0], linear_train[1], linear_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write_to_csv(result, \"result0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Количество гласных/согласных - даёт небольшой буст ~ 0.5%\n",
    "# Окончания - добавление проверки сверху (поверх hash & dollar) ничего не даёт, кажется\n",
    "# Извлекать фичи SelectFromModel\n",
    "# Add hash to the end / beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Добавление символа в начало улучшило результат на 2% при 3,4 граммах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def find_parameters(clf, x_train_l, y_train_l, x_test_l, y_test_l):\n",
    "    count_vect = CountVectorizer(ngram_range=(1,1), decode_error='ignore', lowercase=True)\n",
    "    \n",
    "    x_train_new0 = count_vect.fit_transform(encrypt_array_lengths(x_train_l, np.array([3,4])*2))\n",
    "    x_test_new0 = count_vect.transform(encrypt_array_lengths(x_test_l, np.array([3,4])*2))\n",
    "    \n",
    "    x_train_new0, x_test_new0 = add_feature(isCapitalized, x_train_l, x_test_l, x_train_new0, x_test_new0)\n",
    "    x_train_new0, x_test_new0 = add_feature(vowel_count, x_train_l, x_test_l, x_train_new0, x_test_new0)\n",
    "    x_train_new0, x_test_new0 = add_feature(consonant_count, x_train_l, x_test_l, x_train_new0, x_test_new0)\n",
    "\n",
    "    x_train_new1 = count_vect.fit_transform(to_last_n_letters(x_train_l, 3))\n",
    "    x_test_new1 = count_vect.transform(to_last_n_letters(x_test_l, 3))\n",
    "                                  \n",
    "    x_train_new0, x_test_new0 = (hstack((x_train_new0, x_train_new1)), hstack((x_test_new0, x_test_new1)))\n",
    "                               \n",
    "    clf_config = {           \n",
    "                'penalty' : ['l1', 'l2'], \n",
    "                'dual' : [False],\n",
    "                'max_iter' : np.arange(500,1501,500),\n",
    "                'tol' : [1e-4, 1e-5, 1e-6],\n",
    "                'C': [1, 10],\n",
    "                'n_jobs': [-1],\n",
    "              }\n",
    "    \n",
    "    scorer = make_scorer(score_func=roc_auc_score)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=clf, scoring=scorer, param_grid=clf_config, cv=5, verbose=100)\n",
    "    grid_search.fit(x_train_new0, y_train_l)\n",
    "        \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grid_search.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_l, grid_search.predict(x_test_new0)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#find_parameters(LogisticRegression(), append_front_back(x_train), y_train, append_front_back(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #  0.844\n",
    "from sklearn.linear_model import RidgeClassifier # 0.8577\n",
    "from sklearn.linear_model import RidgeClassifierCV # memory error\n",
    "from sklearn.linear_model import SGDClassifier # 0.869\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier # 0.694\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB # 0.6825\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier # 0.80\n",
    "from sklearn.ensemble import BaggingClassifier # 0.761583612896\n",
    "from sklearn.ensemble import AdaBoostClassifier # 0.780406567954\n",
    "from sklearn.ensemble import ExtraTreesClassifier # 0.790956715791 / 0.79249149196\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# default : 0.781904988147 (n_estimators=10)\n",
    "# n_estimators = 20 : 0.79831297856\n",
    "# max_depth = 10 : 0.948359739662\n",
    "# max_depth = 13 : \n",
    "# max_depth = 15 : 0.94 / 0.84\n",
    "# max_depth = 17 : 0.91\n",
    "# max_depth = 20 : 0.92 / 0.94 / 0.94 / 0.946 / 0.946\n",
    "# max_depth = 25 : 0.915 / 0.910 / 0.941 / 0.910 / 0.924\n",
    "# max_depth = 30 : 0.934 / 0.884 / 0.911\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(full_x, full_y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#print(roc_auc_score(get_result(RidgeClassifier(), \n",
    "#                               append_front_back(x_train), y_train, append_front_back(x_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672819215384\n",
      "CPU times: user 12.9 s, sys: 180 ms, total: 13 s\n",
      "Wall time: 7.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(roc_auc_score(get_result(LogisticRegression(), \n",
    "                              append_front_back(x_train), y_train, append_front_back(x_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#print(roc_auc_score(get_result(RandomForestClassifier(max_depth=20), \n",
    "#                               append_front_back(x_train), y_train, append_front_back(x_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print(roc_auc_score(get_result(BaggingClassifier(), \n",
    "#                                append_front_back(x_train), y_train, append_front_back(x_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#print(roc_auc_score(get_result(AdaBoostClassifier(), \n",
    "#                               append_front_back(x_train), y_train, append_front_back(x_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#print(roc_auc_score(get_result(ExtraTreesClassifier(), \n",
    "#                               append_front_back(x_train), y_train, append_front_back(x_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#print(roc_auc_score(get_result(SGDClassifier(), \n",
    "#                               append_front_back(x_train), y_train, append_front_back(x_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887144398176\n",
      "CPU times: user 16.7 s, sys: 308 ms, total: 17 s\n",
      "Wall time: 9.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(roc_auc_score(get_result(LogisticRegression(), \n",
    "                               append_front_back(x_train), y_train, append_front_back(x_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 s, sys: 488 ms, total: 28.4 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = get_result(LogisticRegression(), \n",
    "                               append_front_back(full_x), full_y, append_front_back(linear_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "write_to_csv(result, \"LogisticRegressionClassifier4-8Ngrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                                  categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 178 23 ftp volvis92\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.feature_extraction.text import CountVectorizer\n",
    ">>> count_vect = CountVectorizer(ngram_range=(3,8), analyzer='char')\n",
    ">>> X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    ">>> X_train_counts.shape\n",
    "print(count_vect.get_feature_names()[8001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
