{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from scipy.sparse import coo_matrix, hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a bit confusing input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train(file_name):\n",
    "    f = open(file_name)\n",
    "    lines = f.readlines()\n",
    "    lines_splitted = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            splitted =  line.split(\",\")\n",
    "            lines_splitted.append([splitted[1], splitted[2].split('+')[0], splitted[2].split('+')[1][0]])\n",
    "        except: \n",
    "            \"wrong lines\"\n",
    "    return pd.DataFrame(lines_splitted, columns=['Word', 'Init', 'Prop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmas_train = read_train(\"data/lemmas_train.csv\")\n",
    "lemmas_test = pd.read_csv(\"data/lemmas_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Init</th>\n",
       "      <th>Prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118635</th>\n",
       "      <td>posereste</td>\n",
       "      <td>posare</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118636</th>\n",
       "      <td>cogestiste</td>\n",
       "      <td>cogestire</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118637</th>\n",
       "      <td>autocorreggerebbero</td>\n",
       "      <td>autocorreggere</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118638</th>\n",
       "      <td>gorgogliassimo</td>\n",
       "      <td>gorgogliare</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118639</th>\n",
       "      <td>desecretaste</td>\n",
       "      <td>desecretare</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Word            Init Prop\n",
       "118635            posereste          posare    V\n",
       "118636           cogestiste       cogestire    V\n",
       "118637  autocorreggerebbero  autocorreggere    V\n",
       "118638       gorgogliassimo     gorgogliare    V\n",
       "118639         desecretaste     desecretare    V"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gettonan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>incidentali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>involtino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>lievi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>comunistizzasse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                X\n",
       "0   1         gettonan\n",
       "1   2      incidentali\n",
       "2   3        involtino\n",
       "3   4            lievi\n",
       "4   5  comunistizzasse"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Will determine part of speech and initial form separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine part of speech via ngrams (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "needed_cols = lemmas_train.columns.drop(['Init'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain, xcv = train_test_split(lemmas_train[needed_cols], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create transformer into ngrams\n",
    "transformer = CountVectorizer(ngram_range=(2, 8), analyzer='char_wb', binary=True, lowercase=True, max_df=0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matrix = transformer.fit_transform(xtrain['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 1.33 s, total: 1min 15s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = LogisticRegression().fit(train_matrix, xtrain['Prop'])\n",
    "predictions = predictor.predict(transformer.transform(xcv['Word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96750674308833451"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(xcv['Prop'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice score ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To determine initial form we will cut the ending and append something to the remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find the same prefix\n",
    "- Count how many symbols to cut\n",
    "- Find what to append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def are_strs(smth1, smth2):\n",
    "    if type(smth1) == type(\"\") and type(smth2) == type(\"\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def same_prefix_length(word1_, word2_):\n",
    "    def for_strs(word1, word2):\n",
    "        retval = 0\n",
    "        for i in range(min(len(word1), len(word2))):\n",
    "            if word1[i] == word2[i]:\n",
    "                retval+=1\n",
    "            else:\n",
    "                break\n",
    "        return retval\n",
    "    \n",
    "    if are_strs(word1_, word2_):\n",
    "        return for_strs(word1_, word2_)\n",
    "    else:\n",
    "        # Consider them as arrays\n",
    "        return np.array([for_strs(w1,w2) for w1,w2 in zip(word1_, word2_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to cut from the end of the word1\n",
    "def to_cut(word1_, word2_):\n",
    "    def for_strs(word1, word2):\n",
    "        return len(word1) - same_prefix_length(word1, word2)\n",
    "    if are_strs(word1_, word2_):\n",
    "        return for_strs(word1_, word2_)\n",
    "    else:\n",
    "        return np.array([for_strs(w1,w2) for w1,w2 in zip(word1_, word2_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What to append to the word1 which has been cut\n",
    "def to_append(word1_, word2_):\n",
    "    def for_strs(word1, word2):\n",
    "        ending = word2[same_prefix_length(word1, word2):]\n",
    "        if ending == \"\":\n",
    "            ending = \"$\"\n",
    "        return ending\n",
    "    if are_strs(word1_, word2_):\n",
    "        return for_strs(word1_, word2_)\n",
    "    else:\n",
    "        return np.array([for_strs(w1,w2) for w1,w2 in zip(word1_, word2_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a relation between words : \"<symbols to cut>_<what to append>\"\n",
    "def get_relation(word1_, word2_):\n",
    "    def for_strs(word1, word2):\n",
    "        return str(to_cut(word1, word2)) + \"_\" + to_append(word1, word2)\n",
    "    if are_strs(word1_, word2_):\n",
    "        return for_strs(word1_, word2_)\n",
    "    else:\n",
    "        return np.array([for_strs(w1,w2) for w1,w2 in zip(word1_, word2_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "ava\n",
      "5_ava\n"
     ]
    }
   ],
   "source": [
    "# Little test\n",
    "s1 = \"blakukurg\"\n",
    "s2 = \"blakava\"\n",
    "s3 = \"black\"\n",
    "s4 = \"hello\"\n",
    "\n",
    "print(same_prefix_length(s1,s2))\n",
    "print(same_prefix_length(s2,s3))\n",
    "print(same_prefix_length(s3,s4))\n",
    "print(to_cut(s1, s2))\n",
    "print(to_append(s1,s2))\n",
    "print(get_relation(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realtions are our classes. We will classify using them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now - cross validation using ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lemmas_train['relation'] = get_relation(lemmas_train['Word'], lemmas_train['Init'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Init</th>\n",
       "      <th>Prop</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vergognerete</td>\n",
       "      <td>vergognare</td>\n",
       "      <td>V</td>\n",
       "      <td>5_are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amnistiavate</td>\n",
       "      <td>amnistiare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>menomazione</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>N</td>\n",
       "      <td>0_$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfaldavamo</td>\n",
       "      <td>sfaldare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfodererei</td>\n",
       "      <td>sfoderare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_are</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word         Init Prop relation\n",
       "0  vergognerete   vergognare    V    5_are\n",
       "1  amnistiavate   amnistiare    V     4_re\n",
       "2   menomazione  menomazione    N      0_$\n",
       "3    sfaldavamo     sfaldare    V     4_re\n",
       "4    sfodererei    sfoderare    V    4_are"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a relation between words : \"<symbols to cut>_<what to append>\"\n",
    "lemmas_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain, xcv = train_test_split(lemmas_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create transformer into ngrams\n",
    "transformer = CountVectorizer(ngram_range=(2, 8), analyzer='char_wb', binary=True, lowercase=True, max_df=0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform word into features matrix where features are ngrams\n",
    "train_matrix = transformer.fit_transform(lemmas_train['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor = LogisticRegression().fit(train_matrix, lemmas_train['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
