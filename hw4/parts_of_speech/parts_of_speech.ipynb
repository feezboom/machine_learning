{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from scipy.sparse import coo_matrix, hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a bit confusing input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train(file_name):\n",
    "    f = open(file_name)\n",
    "    lines = f.readlines()\n",
    "    lines_splitted = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            splitted =  line.split(\",\")\n",
    "            lines_splitted.append([splitted[1], splitted[2].split('+')[0], splitted[2].split('+')[1][0]])\n",
    "        except: \n",
    "            \"wrong lines\"\n",
    "    return pd.DataFrame(lines_splitted, columns=['Word', 'Init', 'Prop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmas_train = read_train(\"data/lemmas_train.csv\")\n",
    "lemmas_test = pd.read_csv(\"data/lemmas_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Init</th>\n",
       "      <th>Prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118635</th>\n",
       "      <td>posereste</td>\n",
       "      <td>posare</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118636</th>\n",
       "      <td>cogestiste</td>\n",
       "      <td>cogestire</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118637</th>\n",
       "      <td>autocorreggerebbero</td>\n",
       "      <td>autocorreggere</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118638</th>\n",
       "      <td>gorgogliassimo</td>\n",
       "      <td>gorgogliare</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118639</th>\n",
       "      <td>desecretaste</td>\n",
       "      <td>desecretare</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Word            Init Prop\n",
       "118635            posereste          posare    V\n",
       "118636           cogestiste       cogestire    V\n",
       "118637  autocorreggerebbero  autocorreggere    V\n",
       "118638       gorgogliassimo     gorgogliare    V\n",
       "118639         desecretaste     desecretare    V"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gettonan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>incidentali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>involtino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>lievi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>comunistizzasse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                X\n",
       "0   1         gettonan\n",
       "1   2      incidentali\n",
       "2   3        involtino\n",
       "3   4            lievi\n",
       "4   5  comunistizzasse"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Will determine part of speech and initial form separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine part of speech via ngrams (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "needed_cols = lemmas_train.columns.drop(['Init'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain, xcv = train_test_split(lemmas_train[needed_cols], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create transformer into ngrams\n",
    "transformer = CountVectorizer(ngram_range=(2, 8), analyzer='char_wb', binary=True, lowercase=True, max_df=0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.75 s, sys: 112 ms, total: 7.86 s\n",
      "Wall time: 7.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_matrix = transformer.fit_transform(xtrain['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 1.62 s, total: 1min 21s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = LogisticRegression().fit(train_matrix, xtrain['Prop'])\n",
    "predictions = predictor.predict(transformer.transform(xcv['Word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96746459878624413"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(xcv['Prop'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice score ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To determine initial form we will cut the ending and append something to the remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find the same prefix\n",
    "- Count how many symbols to cut\n",
    "- Find what to append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def are_strs(smth1, smth2):relations\n",
    "    if type(smth1) == type(\"\") and type(smth2) == type(\"\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def same_prefix_length(word1_, word2_):\n",
    "    def for_strs(word1, word2):\n",
    "        retval = 0\n",
    "        for i in range(min(len(word1), len(word2))):\n",
    "            if word1[i] == word2[i]:\n",
    "                retval+=1\n",
    "            else:\n",
    "                break\n",
    "        return retval\n",
    "    \n",
    "    if are_strs(word1_, word2_):\n",
    "        return for_strs(word1_, word2_)\n",
    "    else:\n",
    "        # Consider them as arrays\n",
    "        return np.array([for_strs(w1,w2) for w1,w2 in zip(word1_, word2_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to cut from the end of the word1\n",
    "def to_cut(word1_, word2_):\n",
    "    def for_strs(word1, word2):\n",
    "        return len(word1) - same_prefix_length(word1, word2)\n",
    "    if are_strs(word1_, word2_):\n",
    "        return for_strs(word1_, word2_)\n",
    "    else:\n",
    "        return np.array([for_strs(w1,w2) for w1,w2 in zip(word1_, word2_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What to append to the word1 which has been cut\n",
    "def to_append(word1_, word2_):\n",
    "    def for_strs(word1, word2):\n",
    "        ending = word2[same_prefix_length(word1, word2):]\n",
    "        if ending == \"\":\n",
    "            ending = \"$\"\n",
    "        return ending\n",
    "    if are_strs(word1_, word2_):\n",
    "        return for_strs(word1_, word2_)\n",
    "    else:\n",
    "        return np.array([for_strs(w1,w2) for w1,w2 in zip(word1_, word2_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a relation between words : \"<symbols to cut>_<what to append>\"\n",
    "def get_relation(word1_, word2_):\n",
    "    def for_strs(word1, word2):\n",
    "        return str(to_cut(word1, word2)) + \"_\" + to_append(word1, word2)\n",
    "    if are_strs(word1_, word2_):\n",
    "        return for_strs(word1_, word2_)\n",
    "    else:\n",
    "        return np.array([for_strs(w1,w2) for w1,w2 in zip(word1_, word2_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "ava\n",
      "5_ava\n"
     ]
    }
   ],
   "source": [
    "# Little test\n",
    "s1 = \"blakukurg\"\n",
    "s2 = \"blakava\"\n",
    "s3 = \"black\"\n",
    "s4 = \"hello\"\n",
    "\n",
    "print(same_prefix_length(s1,s2))\n",
    "print(same_prefix_length(s2,s3))\n",
    "print(same_prefix_length(s3,s4))\n",
    "print(to_cut(s1, s2))\n",
    "print(to_append(s1,s2))\n",
    "print(get_relation(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realtions are our classes. We will classify using them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now - cross validation using ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 4 ms, total: 1.59 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemmas_train['relation'] = get_relation(lemmas_train['Word'], lemmas_train['Init'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Init</th>\n",
       "      <th>Prop</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vergognerete</td>\n",
       "      <td>vergognare</td>\n",
       "      <td>V</td>\n",
       "      <td>5_are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amnistiavate</td>\n",
       "      <td>amnistiare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>menomazione</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>N</td>\n",
       "      <td>0_$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfaldavamo</td>\n",
       "      <td>sfaldare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfodererei</td>\n",
       "      <td>sfoderare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_are</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word         Init Prop relation\n",
       "0  vergognerete   vergognare    V    5_are\n",
       "1  amnistiavate   amnistiare    V     4_re\n",
       "2   menomazione  menomazione    N      0_$\n",
       "3    sfaldavamo     sfaldare    V     4_re\n",
       "4    sfodererei    sfoderare    V    4_are"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a relation between words : \"<symbols to cut>_<what to append>\"\n",
    "lemmas_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84 ms, sys: 0 ns, total: 84 ms\n",
      "Wall time: 83.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xtrain, xcv = train_test_split(lemmas_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Init</th>\n",
       "      <th>Prop</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29629</th>\n",
       "      <td>ciucciante</td>\n",
       "      <td>ciucciare</td>\n",
       "      <td>A</td>\n",
       "      <td>3_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55771</th>\n",
       "      <td>suddividon</td>\n",
       "      <td>suddividere</td>\n",
       "      <td>V</td>\n",
       "      <td>2_ere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62667</th>\n",
       "      <td>gonfiarono</td>\n",
       "      <td>gonfiare</td>\n",
       "      <td>V</td>\n",
       "      <td>3_e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46801</th>\n",
       "      <td>cristalizza</td>\n",
       "      <td>cristalizzare</td>\n",
       "      <td>V</td>\n",
       "      <td>0_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>marsalerete</td>\n",
       "      <td>marsalare</td>\n",
       "      <td>V</td>\n",
       "      <td>5_are</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word           Init Prop relation\n",
       "29629   ciucciante      ciucciare    A     3_re\n",
       "55771   suddividon    suddividere    V    2_ere\n",
       "62667   gonfiarono       gonfiare    V      3_e\n",
       "46801  cristalizza  cristalizzare    V     0_re\n",
       "4422   marsalerete      marsalare    V    5_are"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create transformer into ngrams\n",
    "transformer = CountVectorizer(ngram_range=(2, 5), analyzer='char_wb', binary=True, lowercase=True, max_df=0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.52 s, sys: 4 ms, total: 3.53 s\n",
      "Wall time: 3.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform word into features matrix where features are ngrams\n",
    "train_matrix = transformer.fit_transform(xtrain['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 39s, sys: 36.9 s, total: 37min 16s\n",
      "Wall time: 9min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = LogisticRegression(n_jobs=-1).fit(train_matrix, xtrain['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = predictor.predict(transformer.transform(xcv['Word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3_re' '4_are' '6_are' ..., '3_re' '0_$' '4_re']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92439312204989887"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(xcv['relation'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's transform words -> inital words using relation, which was predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word + relation -> initial word\n",
    "def initiate_words(words, relations):\n",
    "    splitted_relations = np.array([s.split(\"_\") for s in relations])\n",
    "    def initiate_word(word, to_cut, to_append):\n",
    "        if to_cut != '0':\n",
    "            word = word[:-int(to_cut)]\n",
    "        if to_append != \"$\":\n",
    "            word += to_append\n",
    "        return word\n",
    "    \n",
    "    splitted_relations = np.array([(n,s) for n,s in splitted_relations])\n",
    "    initials = np.array([initiate_word(w,p[0],p[1]) for w,p in zip(words,splitted_relations)])\n",
    "    return initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manifestante' 'autorizzare' 'posticipare' ..., 'disserrare' 'idoleggiare'\n",
      " 'abbagliare']\n"
     ]
    }
   ],
   "source": [
    "print(initiate_words(xcv['Word'], xcv['relation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Init</th>\n",
       "      <th>Prop</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44322</th>\n",
       "      <td>manifestante</td>\n",
       "      <td>manifestante</td>\n",
       "      <td>N</td>\n",
       "      <td>0_$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74931</th>\n",
       "      <td>autorizzerai</td>\n",
       "      <td>autorizzare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83121</th>\n",
       "      <td>posticiperanno</td>\n",
       "      <td>posticipare</td>\n",
       "      <td>V</td>\n",
       "      <td>6_are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112942</th>\n",
       "      <td>informasse</td>\n",
       "      <td>informare</td>\n",
       "      <td>V</td>\n",
       "      <td>3_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27818</th>\n",
       "      <td>acrobazia</td>\n",
       "      <td>acrobazia</td>\n",
       "      <td>N</td>\n",
       "      <td>0_$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word          Init Prop relation\n",
       "44322     manifestante  manifestante    N      0_$\n",
       "74931     autorizzerai   autorizzare    V    4_are\n",
       "83121   posticiperanno   posticipare    V    6_are\n",
       "112942      informasse     informare    V     3_re\n",
       "27818        acrobazia     acrobazia    N      0_$"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92443526635198925"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(xcv['Init'], initiate_words(xcv['Word'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's make an a submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict initial form firstly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Init</th>\n",
       "      <th>Prop</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vergognerete</td>\n",
       "      <td>vergognare</td>\n",
       "      <td>V</td>\n",
       "      <td>5_are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amnistiavate</td>\n",
       "      <td>amnistiare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>menomazione</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>N</td>\n",
       "      <td>0_$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfaldavamo</td>\n",
       "      <td>sfaldare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfodererei</td>\n",
       "      <td>sfoderare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_are</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word         Init Prop relation\n",
       "0  vergognerete   vergognare    V    5_are\n",
       "1  amnistiavate   amnistiare    V     4_re\n",
       "2   menomazione  menomazione    N      0_$\n",
       "3    sfaldavamo     sfaldare    V     4_re\n",
       "4    sfodererei    sfoderare    V    4_are"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create transformer into ngrams\n",
    "transformer = CountVectorizer(ngram_range=(2,5), analyzer='char_wb', binary=True, lowercase=True, max_df=0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.05 s, sys: 0 ns, total: 4.05 s\n",
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform word into features matrix where features are ngrams\n",
    "train_matrix = transformer.fit_transform(lemmas_train['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 23s, sys: 45.4 s, total: 46min 9s\n",
      "Wall time: 11min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = LogisticRegression(n_jobs=-1).fit(train_matrix, lemmas_train['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gettonan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>incidentali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>involtino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>lievi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>comunistizzasse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                X\n",
       "0   1         gettonan\n",
       "1   2      incidentali\n",
       "2   3        involtino\n",
       "3   4            lievi\n",
       "4   5  comunistizzasse"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predictor.predict(transformer.transform(lemmas_test['X']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_words = initiate_words(lemmas_test['X'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then predict parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Init</th>\n",
       "      <th>Prop</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vergognerete</td>\n",
       "      <td>vergognare</td>\n",
       "      <td>V</td>\n",
       "      <td>5_are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amnistiavate</td>\n",
       "      <td>amnistiare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>menomazione</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>N</td>\n",
       "      <td>0_$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfaldavamo</td>\n",
       "      <td>sfaldare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfodererei</td>\n",
       "      <td>sfoderare</td>\n",
       "      <td>V</td>\n",
       "      <td>4_are</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word         Init Prop relation\n",
       "0  vergognerete   vergognare    V    5_are\n",
       "1  amnistiavate   amnistiare    V     4_re\n",
       "2   menomazione  menomazione    N      0_$\n",
       "3    sfaldavamo     sfaldare    V     4_re\n",
       "4    sfodererei    sfoderare    V    4_are"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create transformer into ngrams\n",
    "transformer = CountVectorizer(ngram_range=(2, 8), analyzer='char_wb', binary=True, lowercase=True, max_df=0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.96 s, sys: 56 ms, total: 8.01 s\n",
      "Wall time: 8.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_matrix = transformer.fit_transform(lemmas_train['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 1.64 s, total: 1min 42s\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = LogisticRegression().fit(train_matrix, lemmas_train['Prop'])\n",
    "predictions = predictor.predict(transformer.transform(lemmas_test['X']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "props_predicted = pd.DataFrame(data=predictions, columns=[\"props_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here transform into final submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What answer should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>recidivare+V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>recidivare+V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>recidivare+V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>recidivare+V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>recidivare+V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      Category\n",
       "0   1  recidivare+V\n",
       "1   2  recidivare+V\n",
       "2   3  recidivare+V\n",
       "3   4  recidivare+V\n",
       "4   5  recidivare+V"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/sample_submission.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = pd.DataFrame(data=lemmas_test['Id'], columns=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29661"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(props_predicted['props_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final['Category'] = np.array([initial + \"+\" + prop for initial,prop in zip(initial_words, props_predicted['props_pred'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gettonare+V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>incidentale+A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>involtare+V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>liere+N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>comunistizzare+V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id          Category\n",
       "0   1       gettonare+V\n",
       "1   2     incidentale+A\n",
       "2   3       involtare+V\n",
       "3   4           liere+N\n",
       "4   5  comunistizzare+V"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gettonan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>incidentali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>involtino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>lievi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>comunistizzasse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                X\n",
       "0   1         gettonan\n",
       "1   2      incidentali\n",
       "2   3        involtino\n",
       "3   4            lievi\n",
       "4   5  comunistizzasse"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.to_csv(\"results/first_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
